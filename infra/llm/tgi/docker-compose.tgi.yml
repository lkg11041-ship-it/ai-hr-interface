version: "3.8"
services:
  tgi-70b:
    image: ghcr.io/huggingface/text-generation-inference:2.1
    container_name: tgi-70b
    environment:
      - MODEL_ID=meta-llama/Meta-Llama-3.1-70B-Instruct
      - HF_TOKEN=${HF_TOKEN:-}
    command: >
      --max-input-length 8192 --max-total-tokens 9000 --json-output
    ports: ["8002:80"]
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
